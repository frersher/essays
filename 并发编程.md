并发编程
Executor框架(控制线程的启动、执行、关闭)
jdk把工单元和任务执行分离，工作单元包括callable、runnable，而执行机制由Executor提供

Executor框架由三部分组成
1、任务：被执行的任务需要实现3个接口：Runnable、callable接口。runable不会返回结果、callable可以返回结果，所以如果提交的如果是runnable的任务，返回的Future.get()返回null
2、任务的执行：包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。有两个关键的类ThreadPoolEexcutor、ScheduledThreadPoolExecutor
3、异步计算的结果：包括future、future接口的实现类futureTask

futureTask的实现是基于AQS，java.util.concurrnet中的很多可阻塞的类都是基于AQS实现的，AQS是一个同步框架，通过原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。基于AQS实现的有ReentranLock、Semaphore、countDownLatch、FutureTask

Executor：一个接口，其定义了一个接收Runnable对象的方法executor，其方法签名为executor(Runnable command),

ExecutorService：是一个比Executor使用更广泛的子类接口，其提供了生命周期管理的方法，以及可跟踪一个或多个异步任务执行状况返回Future的方法

AbstractExecutorService：ExecutorService执行方法的默认实现

ScheduledExecutorService：一个可定时调度任务的接口

ScheduledThreadPoolExecutor：ScheduledExecutorService的实现，一个可定时调度任务的线程池

ThreadPoolExecutor：线程池，可以通过调用Executors以下静态工厂方法来创建线程池并返回一个ExecutorService对象：

CachedThreadPool：为每一个任务创建线程
FixedThreadPool：一次性的预执行代替了高昂的线程分配，同时也限制了线程的数量
SingleThreadPool：相当于线程数为1的FixThreadPool

线程的优先级
可以用getPriority、setPriority查看和设置



countDownLatch：一个或多个线程等待其他线程完成操作(报表数据清洗的过程中，利用线程池技术，使用多个线程统计全量数据，所有的线程结束，做其他操作)。类似于join(在当前线程中如果调用某个线程的join，当前线程会被阻塞，直到thread线程结束)，countDownLatch只需要检查计数器为零就可以继续继续向下执行

CyclicBarrier：让一组线程达到屏障被阻塞，直到最后一个线程到达时屏障被打开所有线程才会继续执行。

区别：countDownLatch只可以使用一次，CyclicBarrier可以用reset方法重置，并让线程重新执行一次。



**ThreadPoolExecutor 是线程的实现类，也是Executor框架最核心的类**

ThreadPoolExecutor->AbstractExcutorService->ExcutorService->Excutor   继承关系

默认情况下线程池创建完成后并没有线程，而是等到任务来了之后去创建线程  当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；

* corePool：核心线程池大小
* maximumPool：最大线程池大小
* BlockingQueue：任务工作队列
* keepAliveTime：线程活跃时间，如果线程数量大于核心线程数量，多余线程空闲时间超时候被销毁
* RejectedExecutionHandler：当ThreadPoolExecutor关闭或最大线程池已经满了，executor将调用的handler
* ThreadFactory：使用ThreadFactory创建线程，默认使用defaultThreadFactory



Excutor是一个顶层接口只有一个execute方法，返回值为void，参数为Runnable类型，然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等；

要知道**任务提交给线程池之后的处理策略**，这里总结一下主要有4点：

- 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务；
- 如果当前线程池中的线程数目>=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务；
- 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理；
- 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。

http://www.cnblogs.com/dolphin0520/p/3932921.html



**ThreadLocal**
ThreadLocal设计的初衷：提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程。
实现：
  1.每个ThreadLocal类创建一个Map,然后用线程的id作为key，实列对象作为value值，这样可以做到线程隔离的效果（最简单的实现方式）


Executor：一个接口，其定义了一个接收Runnable对象的方法executor，其方法签名为executor(Runnable command),

ExecutorService：是一个比Executor使用更广泛的子类接口，其提供了生命周期管理的方法，以及可跟踪一个或多个异步任务执行状况返回Future的方法

AbstractExecutorService：ExecutorService执行方法的默认实现

ScheduledExecutorService：一个可定时调度任务的接口

ScheduledThreadPoolExecutor：ScheduledExecutorService的实现，一个可定时调度任务的线程池

ThreadPoolExecutor：线程池，可以通过调用Executors以下静态工厂方法来创建线程池并返回一个ExecutorService对象：

CachedThreadPool：为每一个任务创建线程
FixedThreadPool：一次性的预执行代替了高昂的线程分配，同时也限制了线程的数量
SingleThreadPool：相当于线程数为1的FixThreadPool

线程的优先级
可以用getPriority、setPriority查看和设置

synchronized和lock的区别
1）synchronized基于jvm实现的lock通过java代码实现的
2）synchronized假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待，lock分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待
3）lock知道线程有没有成功的获取锁（trylock方法是有返回值的），synchronized无法感知
4）lock必须手动释放锁，synchronized不需要



**JMM(内存模型)**

1、 从JVM运行的视角来看，JVM内存可分为JVM栈、本地方法栈、PC计数器、方法区、堆；前三者是线程私有的。后两者是线程共有的。JVM功能视角来看。jvm分为堆内存、非堆内存与其他

2、线程运行视角来看，jvm分为主内存、线程工作内存





**ConcurrentHashMap**

相对于HashTable  整个加锁的形式，采用了分段加锁的方式，只有hash值在同一个段中的数据才会发生竞争，如果分n段，理论上最高的并发度也是n。segment里面才是真正的hashtable

* get操作：ConcurrentHashMap的读取并发，因为在读取的大多数时候都没有用到锁定。原因是它的get方法里将使用到的共享变量都定义成了volatile，能够在多线程之间保证可见性，可以被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，写入的值不依赖于原值），根据Java内存模型的happen before原则，对volatile字段的写入操作先于读操作(happen-before 保证多线程操作可见性的机制)

* put操作：定位segement，判断segement数组是否需要扩容，只对单个segement扩容，而且是插入数据后扩容(避免扩容后没有数据插入
* size：在put、remove、clean 对modCount++；在统计数量前后判断modCount是否变化，没有变化直接统计；变化了加锁统计。
  
  


ConcurrentHashMap中的HashEntry相对于HashMap中的Entry有一定的差异性：HashEntry中的value以及next都被volatile修饰，这样在多线程读写过程中能够保持它们的可见性，


重入锁
又叫递归锁，指外层获取锁之后，内层的递归函数任有获取锁的代码，但受不影响。可重入锁的最大作用是避免死锁
自旋锁：不可重入锁

锁实现：
AQS构建锁和同步器的框架，AQS是通过双向的FIFO同步队列来完成同步状态的管理，当有线程获取锁失败后，就被添加到队列末尾
AQS的模板方法acquire通过调用子类自定义实现的tryAcquire获取同步状态失败后->将线程构造成Node节点(addWaiter)->将Node节点添加到同步队列对尾(addWaiter)->节点以自旋的方法获取同步状态(acquirQueued)。在节点自旋获取同步状态时，只有其前驱节点是头节点的时候才会尝试获取同步状态，如果该节点的前驱不是头节点或者该节点的前驱节点是头节点单获取同步状态失败，则判断当前线程需要阻塞，如果需要阻塞则需要被唤醒过后才返回。

Node节点用来存放同步失败的线程的引用、等待状态以及前驱和后继节点。

同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点线程释放同步状态时会唤醒后继结点，后继节点会将自己设置为首节点。


**公平锁和非公平锁**

公平锁每次都从同步队列中的第一个节点获取锁 遵循FIFO原则；而非公平锁只要获取了同步状态即成功获取锁，在这个前提下刚释放锁的线程再次获取锁的概率就很大。但是非公平锁的线程切换更少，所以开销更小。

